{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchmetrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MLP\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdistillation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Distiller\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minvariances_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shift_preserving_shape, test_IM\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataLoader\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive - Politecnico di Milano\\Desktop\\eth\\distillinginvariances\\invariances_utils.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchmetrics\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_tensor_as_image\u001b[39m(tensor):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Assuming the input tensor is a square matrix\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchmetrics'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.cnn import SimpleCNN\n",
    "from models.mlp import MLP\n",
    "from distillation_utils import Distiller\n",
    "from invariances_utils import shift_preserving_shape, test_IM\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "4 exp 4 temps\n",
    "self dist\n",
    "self dist shifted\n",
    "mlp vanilla\n",
    "cnn vanilla\n",
    "cnn mlp \n",
    "cnn stupider + mlp\n",
    "fidelity of mlp to t' cross fidelity wrt first cnn - 1 plot\n",
    "\n",
    "accuracy \n",
    "NLL ECE top1 agreement between teacher and student,\n",
    "KL divergence, invariance metric (crossentropy?) -> show patrick it's better\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "num_classes = 10\n",
    "num_conv_layers = 2\n",
    "temperature = 1\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "TRAIN = False\n",
    "device = 'cuda'\n",
    "#np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/938], Loss: 0.4734\n",
      "Epoch [1/10], Step [200/938], Loss: 0.5209\n",
      "Epoch [1/10], Step [300/938], Loss: 0.3167\n",
      "Epoch [1/10], Step [400/938], Loss: 0.2199\n",
      "Epoch [1/10], Step [500/938], Loss: 0.1970\n",
      "Epoch [1/10], Step [600/938], Loss: 0.2205\n",
      "Epoch [1/10], Step [700/938], Loss: 0.2136\n",
      "Epoch [1/10], Step [800/938], Loss: 0.1104\n",
      "Epoch [1/10], Step [900/938], Loss: 0.0864\n",
      "Epoch [2/10], Step [100/938], Loss: 0.0387\n",
      "Epoch [2/10], Step [200/938], Loss: 0.0503\n",
      "Epoch [2/10], Step [300/938], Loss: 0.0605\n",
      "Epoch [2/10], Step [400/938], Loss: 0.2162\n",
      "Epoch [2/10], Step [500/938], Loss: 0.1300\n",
      "Epoch [2/10], Step [600/938], Loss: 0.0471\n",
      "Epoch [2/10], Step [700/938], Loss: 0.1981\n",
      "Epoch [2/10], Step [800/938], Loss: 0.1020\n",
      "Epoch [2/10], Step [900/938], Loss: 0.1371\n",
      "Epoch [3/10], Step [100/938], Loss: 0.1641\n",
      "Epoch [3/10], Step [200/938], Loss: 0.0665\n",
      "Epoch [3/10], Step [300/938], Loss: 0.0585\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0179\n",
      "Epoch [3/10], Step [500/938], Loss: 0.1069\n",
      "Epoch [3/10], Step [600/938], Loss: 0.1754\n",
      "Epoch [3/10], Step [700/938], Loss: 0.1414\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1052\n",
      "Epoch [3/10], Step [900/938], Loss: 0.2123\n",
      "Epoch [4/10], Step [100/938], Loss: 0.1823\n",
      "Epoch [4/10], Step [200/938], Loss: 0.1692\n",
      "Epoch [4/10], Step [300/938], Loss: 0.0308\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0470\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0343\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0589\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0664\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0275\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0771\n",
      "Epoch [5/10], Step [100/938], Loss: 0.0946\n",
      "Epoch [5/10], Step [200/938], Loss: 0.1572\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0412\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0636\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0154\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0104\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0064\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0741\n",
      "Epoch [5/10], Step [900/938], Loss: 0.2368\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0184\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0045\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0171\n",
      "Epoch [6/10], Step [400/938], Loss: 0.1281\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0459\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0485\n",
      "Epoch [6/10], Step [700/938], Loss: 0.0190\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0404\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0346\n",
      "Epoch [7/10], Step [100/938], Loss: 0.1178\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0193\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0804\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0359\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0184\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0328\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0337\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0645\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0399\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0320\n",
      "Epoch [8/10], Step [200/938], Loss: 0.1806\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0677\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0052\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0302\n",
      "Epoch [8/10], Step [600/938], Loss: 0.1452\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0532\n",
      "Epoch [8/10], Step [800/938], Loss: 0.1123\n",
      "Epoch [8/10], Step [900/938], Loss: 0.1079\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0275\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0488\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0864\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0138\n",
      "Epoch [9/10], Step [500/938], Loss: 0.1574\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0542\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0799\n",
      "Epoch [9/10], Step [800/938], Loss: 0.1717\n",
      "Epoch [9/10], Step [900/938], Loss: 0.1044\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0231\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0076\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0588\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0167\n",
      "Epoch [10/10], Step [500/938], Loss: 0.1043\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0086\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0814\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0765\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0766\n",
      "Model saved as saved_models/model!\n",
      "Test Accuracy: 0.9741\n"
     ]
    }
   ],
   "source": [
    "#Obtaining CNN\n",
    "cnn_path = \"saved_models/model\"\n",
    "cnn = SimpleCNN(in_channels=in_channels, num_classes=num_classes, num_conv_layers=num_conv_layers, temperature=temperature).to('cuda:0')\n",
    "if TRAIN:\n",
    "    criterion_cnn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_cnn = torch.optim.Adam(cnn.parameters(), lr=lr)\n",
    "    # model training\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            outputs = cnn(images.to('cuda'))\n",
    "            loss = criterion_cnn(outputs, labels.to('cuda'))\n",
    "\n",
    "            optimizer_cnn.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_cnn.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    # Save the trained model\n",
    "    torch.save(cnn.state_dict(), cnn_path)\n",
    "    print(f\"Model saved as {cnn_path}!\")\n",
    "if not TRAIN:\n",
    "    state_dict = torch.load(cnn_path)\n",
    "    cnn.load_state_dict(state_dict=state_dict)\n",
    "\n",
    "# Testing the model\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = cnn(images.to('cuda'))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to('cuda')).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining CNN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Module.eval() got an unexpected keyword argument 'test_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TRAIN:\n\u001b[0;32m     10\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m MLP(input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m784\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m num_classes, hidden_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m,\n\u001b[0;32m     11\u001b[0m             hidden_layers\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, from_saved_state_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Module.eval() got an unexpected keyword argument 'test_loader'"
     ]
    }
   ],
   "source": [
    "#Loading undistilled MLP\n",
    "if TRAIN:\n",
    "    mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "        hidden_layers= 4, device='cuda')\n",
    "    criterion_mlp = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_mlp = torch.optim.Adam(mlp.parameters(), lr=lr)\n",
    "    mlp.train(train_loader=train_loader, optimizer=optimizer_mlp, criterion=criterion_mlp, \n",
    "              num_epochs=5)\n",
    "if not TRAIN:\n",
    "    mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "mlp.eval(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Correct normal: 0.9684\n",
      "Correct shifted: 0.2821\n",
      "Correct cnn normal: 0.9741\n",
      "Correct cnn shifted: 0.6051\n",
      "\n",
      "tensor(0.5334, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9933, device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.cnn import SimpleCNN\n",
    "from models.mlp import MLP\n",
    "from distillation_utils import Distiller\n",
    "from invariances_utils import shift_preserving_shape, test_IM\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "num_conv_layers = 2\n",
    "temperature = 1\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "TRAIN = False\n",
    "device = 'cuda'\n",
    "#np.random.seed(42)\n",
    "# MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#loading distilled MLP\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "          hidden_layers= 4, device='cuda')\n",
    "\n",
    "cnn_path = \"saved_models/model\"\n",
    "state_dict = torch.load(cnn_path)\n",
    "cnn = SimpleCNN(in_channels=in_channels, num_classes=num_classes, num_conv_layers=num_conv_layers, temperature=temperature).to('cuda:0')\n",
    "cnn.load_state_dict(state_dict=state_dict)\n",
    "distiller = Distiller(student=mlp_student, teacher=cnn, device='cuda', lr=0.001)\n",
    "\n",
    "if TRAIN:\n",
    "    distiller.distill(train_loader, test_loader)\n",
    "    torch.save(distiller.get_student().state_dict(), \"newdistillmethod/distiller\")  \n",
    "else:\n",
    "    state_dict = torch.load(\"newdistillmethod/distiller\")\n",
    "    distiller.get_student().load_state_dict(state_dict=state_dict)\n",
    "    #distiller.eval_student(train_loader)\n",
    "test_IM(test_loader, distiller.get_student(), cnn, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n"
     ]
    }
   ],
   "source": [
    "#loading distilled MLP\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "          hidden_layers= 4, device='cuda')\n",
    "distiller = Distiller(student=mlp_student, teacher=cnn, device='cuda', lr=0.001)\n",
    "if TRAIN:\n",
    "    distiller.distill(train_loader, test_loader)\n",
    "    torch.save(distiller.get_student().state_dict(), \"newdistillmethod/distiller\")  \n",
    "else:\n",
    "    state_dict = torch.load(\"newdistillmethod/distiller\")\n",
    "    distiller.get_student().load_state_dict(state_dict=state_dict)\n",
    "distiller.get_student().eval_loop(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_IM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_student\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive - Politecnico di Milano\\Desktop\\eth\\distillinginvariances\\invariances_utils.py:131\u001b[0m, in \u001b[0;36mtest_IM\u001b[1;34m(loader, model)\u001b[0m\n\u001b[0;32m    129\u001b[0m     unshifted_labels \u001b[38;5;241m=\u001b[39m model(non_shifted)\n\u001b[0;32m    130\u001b[0m     shifted_labels \u001b[38;5;241m=\u001b[39m model(shifted)\n\u001b[1;32m--> 131\u001b[0m correct_shifted \u001b[38;5;241m=\u001b[39m correct_shifted \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43munshifted_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    132\u001b[0m correct_normal \u001b[38;5;241m=\u001b[39m correct_normal \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mmax(shifted_labels, dim\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m    133\u001b[0m invariance_measures\u001b[38;5;241m.\u001b[39mappend(invariance_measure(unshifted_labels, shifted_labels)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "test_IM(test_loader, distiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Test Accuracy: 0.9612\n",
      "tensor(0.8725, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Not using softmax\n",
      "tensor(0.8738, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "hfafu\n",
      "Epoch [1/5], Step [100/938], Student Loss : 0.1635, Total Loss: 0.0442\n",
      "Epoch [1/5], Step [200/938], Student Loss : 0.0570, Total Loss: 0.0225\n",
      "Epoch [1/5], Step [300/938], Student Loss : 0.3554, Total Loss: 0.1328\n",
      "Epoch [1/5], Step [400/938], Student Loss : 0.1317, Total Loss: 0.1042\n",
      "Epoch [1/5], Step [500/938], Student Loss : 0.2529, Total Loss: 0.0886\n",
      "Epoch [1/5], Step [600/938], Student Loss : 0.0233, Total Loss: 0.0219\n",
      "Epoch [1/5], Step [700/938], Student Loss : 0.3350, Total Loss: 0.2302\n",
      "Epoch [1/5], Step [800/938], Student Loss : 0.0820, Total Loss: 0.0284\n",
      "Epoch [1/5], Step [900/938], Student Loss : 0.4317, Total Loss: 0.0910\n",
      "Epoch [2/5], Step [100/938], Student Loss : 0.1460, Total Loss: 0.3145\n",
      "Epoch [2/5], Step [200/938], Student Loss : 0.6121, Total Loss: 0.2191\n",
      "Epoch [2/5], Step [300/938], Student Loss : 0.1448, Total Loss: 0.0714\n",
      "Epoch [2/5], Step [400/938], Student Loss : 0.3349, Total Loss: 0.0413\n",
      "Epoch [2/5], Step [500/938], Student Loss : 0.2626, Total Loss: 0.0921\n",
      "Epoch [2/5], Step [600/938], Student Loss : 0.1225, Total Loss: 0.0426\n",
      "Epoch [2/5], Step [700/938], Student Loss : 0.2021, Total Loss: 0.0963\n",
      "Epoch [2/5], Step [800/938], Student Loss : 0.4059, Total Loss: 0.1832\n",
      "Epoch [2/5], Step [900/938], Student Loss : 0.6294, Total Loss: 0.0494\n",
      "Epoch [3/5], Step [100/938], Student Loss : 0.0622, Total Loss: 0.0631\n",
      "Epoch [3/5], Step [200/938], Student Loss : 0.1702, Total Loss: 0.1661\n",
      "Epoch [3/5], Step [300/938], Student Loss : 0.7188, Total Loss: 0.0331\n",
      "Epoch [3/5], Step [400/938], Student Loss : 0.2593, Total Loss: 0.1580\n",
      "Epoch [3/5], Step [500/938], Student Loss : 0.0707, Total Loss: 0.0276\n",
      "Epoch [3/5], Step [600/938], Student Loss : 0.0142, Total Loss: 0.0164\n",
      "Epoch [3/5], Step [700/938], Student Loss : 0.0015, Total Loss: 0.0054\n",
      "Epoch [3/5], Step [800/938], Student Loss : 0.2647, Total Loss: 0.0304\n",
      "Epoch [3/5], Step [900/938], Student Loss : 0.0132, Total Loss: 0.0099\n",
      "Epoch [4/5], Step [100/938], Student Loss : 0.1007, Total Loss: 0.1005\n",
      "Epoch [4/5], Step [200/938], Student Loss : 0.1186, Total Loss: 0.0490\n",
      "Epoch [4/5], Step [300/938], Student Loss : 0.3508, Total Loss: 0.0401\n",
      "Epoch [4/5], Step [400/938], Student Loss : 0.6503, Total Loss: 0.0766\n",
      "Epoch [4/5], Step [500/938], Student Loss : 0.2393, Total Loss: 0.0492\n",
      "Epoch [4/5], Step [600/938], Student Loss : 0.1205, Total Loss: 0.0840\n",
      "Epoch [4/5], Step [700/938], Student Loss : 0.0358, Total Loss: 0.0221\n",
      "Epoch [4/5], Step [800/938], Student Loss : 1.2560, Total Loss: 0.1168\n",
      "Epoch [4/5], Step [900/938], Student Loss : 0.0926, Total Loss: 0.1000\n",
      "Epoch [5/5], Step [100/938], Student Loss : 0.0374, Total Loss: 0.0186\n",
      "Epoch [5/5], Step [200/938], Student Loss : 0.1427, Total Loss: 0.1758\n",
      "Epoch [5/5], Step [300/938], Student Loss : 0.1114, Total Loss: 0.0248\n",
      "Epoch [5/5], Step [400/938], Student Loss : 0.0207, Total Loss: 0.0445\n",
      "Epoch [5/5], Step [500/938], Student Loss : 0.2438, Total Loss: 0.0220\n",
      "Epoch [5/5], Step [600/938], Student Loss : 0.2129, Total Loss: 0.1495\n",
      "Epoch [5/5], Step [700/938], Student Loss : 0.3182, Total Loss: 0.0395\n",
      "Epoch [5/5], Step [800/938], Student Loss : 0.2660, Total Loss: 0.0610\n",
      "Epoch [5/5], Step [900/938], Student Loss : 0.0518, Total Loss: 0.0222\n",
      "Student loss: 0.23638089361807538\n",
      "Distillation loss: 0.07954516015532943\n",
      "Total loss: 0.07954516015532943\n",
      "saved model\n",
      "Test Accuracy: 0.9566\n"
     ]
    }
   ],
   "source": [
    "#Self distilling MLP (only from loaded data)\n",
    "\n",
    "#Self distillation: mlp_student and mlp teacher coincide #TODO CHECK\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "mlp_student.eval(test_loader)\n",
    "print(test_IM(test_loader, mlp_student))\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "print(test_IM(test_loader, mlp_teacher))\n",
    "\n",
    "if TRAIN:\n",
    "    selfdistiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    selfdistiller.distill(train_loader, 5, \"saved_models_selfdistill/\")\n",
    "    selfdistiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    selfdistiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_selfdistill/distiller')\n",
    "    selfdistiller.test_step(test_loader=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8889, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, selfdistiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Not using softmax\n",
      "tensor(0.8729, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "hfafu\n",
      "Epoch [1/5], Step [100/938], Student Loss : 27.8136, Total Loss: 8.6661\n",
      "Epoch [1/5], Step [200/938], Student Loss : 188.4176, Total Loss: 11.5220\n",
      "Epoch [1/5], Step [300/938], Student Loss : 662.5803, Total Loss: 13.8150\n",
      "Epoch [1/5], Step [400/938], Student Loss : 752.3962, Total Loss: 14.6692\n",
      "Epoch [1/5], Step [500/938], Student Loss : 609.8974, Total Loss: 14.1995\n",
      "Epoch [1/5], Step [600/938], Student Loss : 2639.6240, Total Loss: 15.4462\n",
      "Epoch [1/5], Step [700/938], Student Loss : 2322.1643, Total Loss: 14.6260\n",
      "Epoch [1/5], Step [800/938], Student Loss : 2393.5117, Total Loss: 14.2670\n",
      "Epoch [1/5], Step [900/938], Student Loss : 2528.3132, Total Loss: 17.2357\n",
      "Epoch [2/5], Step [100/938], Student Loss : 2206.9958, Total Loss: 14.5140\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[0;32m     10\u001b[0m     mlp_mlp_distiller \u001b[38;5;241m=\u001b[39m Distiller(student\u001b[38;5;241m=\u001b[39mmlp_student, teacher\u001b[38;5;241m=\u001b[39mmlp_teacher, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     \u001b[43mmlp_mlp_distiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models_mlpfrommlp/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     mlp_mlp_distiller\u001b[38;5;241m.\u001b[39mtest_step(test_loader\u001b[38;5;241m=\u001b[39mtest_loader)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TRAIN:\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive - Politecnico di Milano\\Desktop\\eth\\distillinginvariances\\distillation_utils.py:41\u001b[0m, in \u001b[0;36mDistiller.distill\u001b[1;34m(self, train_dataloader, epochs, save_path_folder)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Train the student network through one feed forward.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y)  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:363\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\_functional_tensor.py:928\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    927\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Self Distillation\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda')\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "print(test_IM(test_loader, mlp_teacher))\n",
    "\n",
    "if TRAIN:\n",
    "    mlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    mlp_mlp_distiller.distill(train_loader, 5, \"saved_models_mlpfrommlp/\")\n",
    "    mlp_mlp_distiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    mlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_mlpfrommlp/distiller')\n",
    "    mlp_mlp_distiller.test_step(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, mlp_mlp_distiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset that combines MNIST and additional data\n",
    "class ShiftAugmentedMNIST(Dataset):\n",
    "    def __init__(self, mnist_dataset, translation_times : int = 5, max_shift : int = 5):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        directions = [\"u\",\"d\",\"l\",\"r\"]\n",
    "        self.translations = []\n",
    "        for i in range(len(self.mnist_dataset)):\n",
    "            img, label = self.mnist_dataset[i]\n",
    "            img = img.squeeze()\n",
    "            for t in range(translation_times):\n",
    "                sh = shift_preserving_shape(img, direction=directions[np.random.randint(0,4)],\n",
    "                                            max_shift=max_shift).unsqueeze(0)\n",
    "                if sh is not None:\n",
    "                    self.translations.append((sh, label))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self.mnist_dataset):\n",
    "            return self.mnist_dataset[index]\n",
    "        else:\n",
    "            return self.translations[index - len(self.mnist_dataset)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset) + len(self.translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset with shift invariance\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_augmented_dataset = ShiftAugmentedMNIST(train_dataset)\n",
    "train_augmented_loader = DataLoader(dataset=train_augmented_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating MLP trained on invariance data\n",
    "if TRAIN:\n",
    "    shift_invariant_mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "        hidden_layers= 4, device='cuda')\n",
    "    criterion_mlp = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_mlp = torch.optim.Adam(shift_invariant_mlp.parameters(), lr=lr)\n",
    "    shift_invariant_mlp.train(train_loader=train_augmented_loader, optimizer=optimizer_mlp, criterion=criterion_mlp, \n",
    "              num_epochs=5, save_path_folder = \"saved_models_shiftinvariantmlp\")\n",
    "if not TRAIN:\n",
    "    shift_invariant_mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models_shiftinvariantmlp/mlp\")\n",
    "shift_invariant_mlp.eval(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, shift_invariant_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Not using softmax\n",
      "Invariance of teacher:tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch [1/5], Step [100/938], Student Loss : 3.4604, Total Loss: 15.6608\n",
      "Epoch [1/5], Step [200/938], Student Loss : 2.1550, Total Loss: 3.0418\n",
      "Epoch [1/5], Step [300/938], Student Loss : 0.2299, Total Loss: 1.6676\n",
      "Epoch [1/5], Step [400/938], Student Loss : 0.9416, Total Loss: 2.1623\n",
      "Epoch [1/5], Step [500/938], Student Loss : 1.0407, Total Loss: 3.0659\n",
      "Epoch [1/5], Step [600/938], Student Loss : 0.8709, Total Loss: 2.0034\n",
      "Epoch [1/5], Step [700/938], Student Loss : 0.2186, Total Loss: 1.1539\n",
      "Epoch [1/5], Step [800/938], Student Loss : 0.1631, Total Loss: 1.0458\n",
      "Epoch [1/5], Step [900/938], Student Loss : 0.4773, Total Loss: 1.4397\n",
      "Epoch [2/5], Step [100/938], Student Loss : 0.3148, Total Loss: 1.6611\n",
      "Epoch [2/5], Step [200/938], Student Loss : 0.3473, Total Loss: 3.0052\n",
      "Epoch [2/5], Step [300/938], Student Loss : 0.5968, Total Loss: 1.6403\n",
      "Epoch [2/5], Step [400/938], Student Loss : 0.0611, Total Loss: 0.9886\n",
      "Epoch [2/5], Step [500/938], Student Loss : 0.2777, Total Loss: 0.6863\n",
      "Epoch [2/5], Step [600/938], Student Loss : 0.1147, Total Loss: 1.2115\n",
      "Epoch [2/5], Step [700/938], Student Loss : 0.2950, Total Loss: 1.3145\n",
      "Epoch [2/5], Step [800/938], Student Loss : 0.1428, Total Loss: 0.8588\n",
      "Epoch [2/5], Step [900/938], Student Loss : 0.2483, Total Loss: 1.2941\n",
      "Epoch [3/5], Step [100/938], Student Loss : 0.0389, Total Loss: 0.7593\n",
      "Epoch [3/5], Step [200/938], Student Loss : 0.0489, Total Loss: 0.6878\n",
      "Epoch [3/5], Step [300/938], Student Loss : 0.0317, Total Loss: 0.6488\n",
      "Epoch [3/5], Step [400/938], Student Loss : 0.0909, Total Loss: 0.9245\n",
      "Epoch [3/5], Step [500/938], Student Loss : 0.0056, Total Loss: 0.3832\n",
      "Epoch [3/5], Step [600/938], Student Loss : 0.0018, Total Loss: 1.0154\n",
      "Epoch [3/5], Step [700/938], Student Loss : 0.1075, Total Loss: 0.7496\n",
      "Epoch [3/5], Step [800/938], Student Loss : 0.2300, Total Loss: 1.1219\n",
      "Epoch [3/5], Step [900/938], Student Loss : 0.2168, Total Loss: 0.7760\n",
      "Epoch [4/5], Step [100/938], Student Loss : 0.0038, Total Loss: 0.4558\n",
      "Epoch [4/5], Step [200/938], Student Loss : 0.3084, Total Loss: 0.5788\n",
      "Epoch [4/5], Step [300/938], Student Loss : 0.1226, Total Loss: 0.4086\n",
      "Epoch [4/5], Step [400/938], Student Loss : 0.1236, Total Loss: 0.5367\n",
      "Epoch [4/5], Step [500/938], Student Loss : 0.1287, Total Loss: 0.3545\n",
      "Epoch [4/5], Step [600/938], Student Loss : 0.0657, Total Loss: 0.2820\n",
      "Epoch [4/5], Step [700/938], Student Loss : 0.0631, Total Loss: 0.4085\n",
      "Epoch [4/5], Step [800/938], Student Loss : 0.1821, Total Loss: 0.6157\n",
      "Epoch [4/5], Step [900/938], Student Loss : 0.0203, Total Loss: 0.4708\n",
      "Epoch [5/5], Step [100/938], Student Loss : 0.0946, Total Loss: 0.5327\n",
      "Epoch [5/5], Step [200/938], Student Loss : 0.0441, Total Loss: 0.3774\n",
      "Epoch [5/5], Step [300/938], Student Loss : 0.0548, Total Loss: 0.3114\n",
      "Epoch [5/5], Step [400/938], Student Loss : 0.0324, Total Loss: 0.4279\n",
      "Epoch [5/5], Step [500/938], Student Loss : 0.0542, Total Loss: 0.3380\n",
      "Epoch [5/5], Step [600/938], Student Loss : 0.3306, Total Loss: 0.4517\n",
      "Epoch [5/5], Step [700/938], Student Loss : 0.2335, Total Loss: 0.9449\n",
      "Epoch [5/5], Step [800/938], Student Loss : 0.0422, Total Loss: 0.4800\n",
      "Epoch [5/5], Step [900/938], Student Loss : 0.0081, Total Loss: 0.6415\n",
      "Student loss: 0.3253565156754727\n",
      "Distillation loss: 1.3241054289870793\n",
      "Total loss: 1.3241054289870793\n",
      "saved model\n",
      "Test Accuracy: 0.9844\n",
      "Test Accuracy: 0.9766\n",
      "Test Accuracy: 0.9740\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9750\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9705\n",
      "Test Accuracy: 0.9656\n",
      "Test Accuracy: 0.9645\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9615\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9583\n",
      "Test Accuracy: 0.9580\n",
      "Test Accuracy: 0.9568\n",
      "Test Accuracy: 0.9566\n",
      "Test Accuracy: 0.9539\n",
      "Test Accuracy: 0.9508\n",
      "Test Accuracy: 0.9494\n",
      "Test Accuracy: 0.9503\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9469\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9456\n",
      "Test Accuracy: 0.9459\n",
      "Test Accuracy: 0.9456\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9466\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9460\n",
      "Test Accuracy: 0.9457\n",
      "Test Accuracy: 0.9468\n",
      "Test Accuracy: 0.9461\n",
      "Test Accuracy: 0.9463\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9463\n",
      "Test Accuracy: 0.9464\n",
      "Test Accuracy: 0.9473\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9490\n",
      "Test Accuracy: 0.9487\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9480\n",
      "Test Accuracy: 0.9487\n",
      "Test Accuracy: 0.9488\n",
      "Test Accuracy: 0.9498\n",
      "Test Accuracy: 0.9493\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9495\n",
      "Test Accuracy: 0.9498\n",
      "Test Accuracy: 0.9504\n",
      "Test Accuracy: 0.9499\n",
      "Test Accuracy: 0.9495\n",
      "Test Accuracy: 0.9490\n",
      "Test Accuracy: 0.9486\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9480\n",
      "Test Accuracy: 0.9483\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9472\n",
      "Test Accuracy: 0.9475\n",
      "Test Accuracy: 0.9475\n",
      "Test Accuracy: 0.9474\n",
      "Test Accuracy: 0.9473\n",
      "Test Accuracy: 0.9476\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9483\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9481\n",
      "Test Accuracy: 0.9477\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9491\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9503\n",
      "Test Accuracy: 0.9509\n",
      "Test Accuracy: 0.9513\n",
      "Test Accuracy: 0.9515\n",
      "Test Accuracy: 0.9520\n",
      "Test Accuracy: 0.9522\n",
      "Test Accuracy: 0.9524\n",
      "Test Accuracy: 0.9526\n",
      "Test Accuracy: 0.9531\n",
      "Test Accuracy: 0.9523\n",
      "Test Accuracy: 0.9514\n",
      "Test Accuracy: 0.9511\n",
      "Test Accuracy: 0.9505\n",
      "Test Accuracy: 0.9505\n",
      "Test Accuracy: 0.9504\n",
      "Test Accuracy: 0.9509\n",
      "Test Accuracy: 0.9514\n",
      "Test Accuracy: 0.9519\n",
      "Test Accuracy: 0.9524\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9522\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9528\n",
      "Test Accuracy: 0.9531\n",
      "Test Accuracy: 0.9536\n",
      "Test Accuracy: 0.9540\n",
      "Test Accuracy: 0.9544\n",
      "Test Accuracy: 0.9547\n",
      "Test Accuracy: 0.9551\n",
      "Test Accuracy: 0.9553\n",
      "Test Accuracy: 0.9555\n",
      "Test Accuracy: 0.9558\n",
      "Test Accuracy: 0.9562\n",
      "Test Accuracy: 0.9562\n",
      "Test Accuracy: 0.9566\n",
      "Test Accuracy: 0.9569\n",
      "Test Accuracy: 0.9573\n",
      "Test Accuracy: 0.9575\n",
      "Test Accuracy: 0.9579\n",
      "Test Accuracy: 0.9580\n",
      "Test Accuracy: 0.9583\n",
      "Test Accuracy: 0.9586\n",
      "Test Accuracy: 0.9588\n",
      "Test Accuracy: 0.9588\n",
      "Test Accuracy: 0.9591\n",
      "Test Accuracy: 0.9593\n",
      "Test Accuracy: 0.9595\n",
      "Test Accuracy: 0.9593\n",
      "Test Accuracy: 0.9594\n",
      "Test Accuracy: 0.9595\n",
      "Test Accuracy: 0.9594\n",
      "Test Accuracy: 0.9597\n",
      "Test Accuracy: 0.9600\n",
      "Test Accuracy: 0.9603\n",
      "Test Accuracy: 0.9606\n",
      "Test Accuracy: 0.9608\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9612\n",
      "Test Accuracy: 0.9614\n",
      "Test Accuracy: 0.9616\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9622\n",
      "Test Accuracy: 0.9623\n",
      "Test Accuracy: 0.9625\n",
      "Test Accuracy: 0.9625\n",
      "Test Accuracy: 0.9621\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9615\n",
      "Test Accuracy: 0.9613\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "#Train student model on MLP trained on invariance data \n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda')\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models_shiftinvariantmlp/mlp\")\n",
    "print(\"Invariance of teacher:\" + str(test_IM(test_loader, mlp_teacher)))\n",
    "\n",
    "if TRAIN:\n",
    "    shiftinvmlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    shiftinvmlp_mlp_distiller.distill(train_loader, 5, \"saved_models_mlpfromshiftinvariantmlp/\")\n",
    "    shiftinvmlp_mlp_distiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    shiftinvmlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_mlpfromshiftinvariantmlp/distiller')\n",
    "    shiftinvmlp_mlp_distiller.test_step(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9111, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, shiftinvmlp_mlp_distiller.get_student())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanilla MLP -> 0.9\n",
    "CNN over MLP -> 0.6\n",
    "\n",
    "Self-distilled MLP -> 0.5\n",
    "MLP over MLP -> 0.5\n",
    "\n",
    "distilled MLP over data augmented MLP on non augmented dataset -> 0.48\n",
    "\n",
    "extended MNIST and split the dataset in 2 -> train 2 independent CNNs (or use low teacher fidelity, KL between teachers should be high) get t and t', distill to s and s', compute agreement between t and s' \n",
    "\n",
    "repeat process for all temperatures [1,4,8,16] and all random seeds \n",
    "\n",
    "Data augmented MLP -> 0.09\n",
    "(distilled MLP over data augmented MLP on augmented dataset -> 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change IM measure with temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "FABIAN TO DO\n",
    "----------------------\n",
    "METRICS:\n",
    "- test agreement metrics \n",
    "- indipendent metrics (ECE, NLL, topk) -> consistent with the literature \n",
    "we need to add to the eval process these metrics + have a table of consistence with the literature (what are those metrics for a good mlp/cnn/distilled mlp)\n",
    "EXPERIMENTS\n",
    "- Train 2 independent students with the same teacher, you compare the fidelities, if the 2 students have comparable fidelities they agree with the teacher because they generalize well \n",
    "train 2 students as the above cell + compute agreement metrics\n",
    "- test distillation with different temperatures: fix temperatures 1 4 8 16\n",
    "- different MLP model size + test that the mlp is lower in flops\n",
    "------------------------\n",
    "ALREADY DONE:\n",
    "- compute agreement metrics: how much has the student learnt to predict in the same way as the teacher. \n",
    "compute_agreement(student_model, teacher_model) - most of this code already written by Patrick: deepsets/test\n",
    "_____________________________________\n",
    "4 exp 4 temps\n",
    "self dist\n",
    "self dist shifted\n",
    "mlp vanilla\n",
    "cnn vanilla\n",
    "cnn mlp \n",
    "cnn stupider + mlp\n",
    "fidelity of mlp to t' cross fidelity wrt first cnn - 1 plot\n",
    "\n",
    "accuracy NLL ECE top1 agreement between teacher and student, KL divergence, invariance metric (crossentropy?) -> show patrick it's better\n",
    "\n",
    "\n",
    "NICOLE TO DO:\n",
    "---------------\n",
    "- try with bigger filter and bigger max pooling\n",
    "- change IM metric\n",
    "\n",
    "- rerun all experiments and make pretty plots\n",
    "- large, heavy, regularized MLP - create a large, heavy, regularized MLP and distill with that\n",
    "- scale: extended MNIST CIFAR-10 (but cumbersome)\n",
    "- uncertainties : different seeds \n",
    "- 42 101 121 240 308 random seeds \n",
    "- non shifted training set + mlp, mlp with distillation on a cnn, run those over test dataset that's shifted -> expect better performance on mlp dist on cnn\n",
    "- give shifted validation set performance (validation set loss)\n",
    "- test val set accuracy with alpha different\n",
    "\n",
    " \n",
    "TO DO TOMORROW:\n",
    "- understand the softmax thing\n",
    "- plotting with different temperatures\n",
    "\n",
    "We need to have consistent:\n",
    "- training\n",
    "- distillation\n",
    "- indipendent metrics (ECE, NLL, topk) -> consistent with the literature \n",
    "- fidelity metrics\n",
    "----------------------------\n",
    "- self distilling mlp\n",
    "- fix the distillation loss problem\n",
    "- distill an mlp over an mlp\n",
    "- train an mlp independently on shifted data - compares with unshifted but distilled \n",
    "------------------------------------------\n",
    "\n",
    "\n",
    "the model actually learns invariances through the teacher -> all of these results hold\n",
    "\n",
    "\n",
    "ECE,  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
