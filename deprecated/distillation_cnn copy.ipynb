{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models.cnn import SimpleCNN\n",
    "from models.mlp import MLP\n",
    "from distillation_utils import Distiller\n",
    "from invariances_utils import shift_preserving_shape\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from invariances_utils import test_IM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 1\n",
    "num_classes = 10\n",
    "num_conv_layers = 2\n",
    "temperature = 1\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "TRAIN = False\n",
    "device = 'cuda'\n",
    "#np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "#Obtaining CNN\n",
    "cnn_path = \"saved_models/model\"\n",
    "cnn = SimpleCNN(in_channels=in_channels, num_classes=num_classes, num_conv_layers=num_conv_layers, temperature=temperature).to('cuda:0')\n",
    "if TRAIN:\n",
    "    criterion_cnn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_cnn = torch.optim.Adam(cnn.parameters(), lr=lr)\n",
    "    # model training\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            outputs = cnn(images.to('cuda'))\n",
    "            loss = criterion_cnn(outputs, labels.to('cuda'))\n",
    "\n",
    "            optimizer_cnn.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_cnn.step()\n",
    "\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
    "    # Save the trained model\n",
    "    torch.save(cnn.state_dict(), cnn_path)\n",
    "    print(f\"Model saved as {cnn_path}!\")\n",
    "if not TRAIN:\n",
    "    state_dict = torch.load(cnn_path)\n",
    "    cnn.load_state_dict(state_dict=state_dict)\n",
    "\n",
    "# Testing the model\n",
    "cnn.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = cnn(images.to('cuda'))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.to('cuda')).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TRAIN:\n\u001b[0;32m     10\u001b[0m     mlp \u001b[38;5;241m=\u001b[39m MLP(input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m784\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m num_classes, hidden_size\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2048\u001b[39m,\n\u001b[0;32m     11\u001b[0m             hidden_layers\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, from_saved_state_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msaved_models/mlp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive - Politecnico di Milano\\Desktop\\eth\\distillinginvariances\\models\\mlp.py:85\u001b[0m, in \u001b[0;36mMLP.eval\u001b[1;34m(self, test_loader)\u001b[0m\n\u001b[0;32m     83\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     84\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m     86\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m)\n\u001b[0;32m     87\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(images\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:172\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    170\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mByteTensor):\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdefault_float_dtype)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Loading undistilled MLP\n",
    "if TRAIN:\n",
    "    mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "        hidden_layers= 4, device='cuda')\n",
    "    criterion_mlp = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_mlp = torch.optim.Adam(mlp.parameters(), lr=lr)\n",
    "    mlp.train(train_loader=train_loader, optimizer=optimizer_mlp, criterion=criterion_mlp, \n",
    "              num_epochs=5)\n",
    "if not TRAIN:\n",
    "    mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "mlp.eval(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "hfafu\n",
      "Epoch [1/5], Step [100/938], Student Loss : 1.7319, Total Loss: -2.4423\n",
      "Epoch [1/5], Step [200/938], Student Loss : 1.6166, Total Loss: -2.4481\n",
      "Epoch [1/5], Step [300/938], Student Loss : 1.6348, Total Loss: -2.4480\n",
      "Epoch [1/5], Step [400/938], Student Loss : 1.5709, Total Loss: -2.4520\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TRAIN:\n\u001b[0;32m      5\u001b[0m     distiller \u001b[38;5;241m=\u001b[39m Distiller(student\u001b[38;5;241m=\u001b[39mmlp_student, teacher\u001b[38;5;241m=\u001b[39mcnn, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m     \u001b[43mdistiller\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TRAIN:\n\u001b[0;32m      8\u001b[0m     distiller \u001b[38;5;241m=\u001b[39m Distiller(student\u001b[38;5;241m=\u001b[39mmlp_student, teacher\u001b[38;5;241m=\u001b[39mcnn, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[0;32m      9\u001b[0m                         load_student_from_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaved_models/distiller\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicol\\OneDrive - Politecnico di Milano\\Desktop\\eth\\distillinginvariances\\distillation_utils.py:41\u001b[0m, in \u001b[0;36mDistiller.distill\u001b[1;34m(self, train_dataloader, epochs, save_path_folder)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     39\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Train the student network through one feed forward.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y)  \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     42\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     43\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:170\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    169\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 170\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    172\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loading distilled MLP\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "          hidden_layers= 4, device='cuda')\n",
    "if TRAIN:\n",
    "    distiller = Distiller(student=mlp_student, teacher=cnn, device='cuda', lr=0.0001)\n",
    "    distiller.distill(train_loader, 20, \"saved_models/\")\n",
    "if not TRAIN:\n",
    "    distiller = Distiller(student=mlp_student, teacher=cnn, device='cuda', lr=0.0001,\n",
    "                        load_student_from_path = 'saved_models/distiller')\n",
    "distiller.test_step(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morning take:\n",
    "what we were doing before was really wrong, but we consistently obtained good results wrt training and distillation.\n",
    "To use the KL divergence you either need to have the log target specified in the KL formula and use the log softmax in both input and target or you can also have only the input in log space.\n",
    "\n",
    "if you have the input in log space and the target not in log space: what happens is that you obtain nan predictions for the student, and thus a nan loss to backpropagate. I have tried to not backpropagate when we obtain a null loss but that doesn't solve the problem. \n",
    "I still need to pinpoint why this happens but I'm fairly sure that it is because the gradients vanish\n",
    "\n",
    "if you have both inputs and targets using the log softmax (what you suggested) both the student and the distillation loss goes up instead of going down. It may go down for a short amount of time, but it happens that at some point in the training the student loss explodes (to numers like 10000+) and the end validation accuracy is 0.1. In some runs you are lucky enough that this doesn't happen and the network actually trains but those are rare. I implemented gradient clipping (limit gradients to 1.0) and it seems to help solve the problem. Though sometimes the student network gets initialized in a way so that the student loss is already very high from the start (1000+) and from those runs it doesn't seem to recover.\n",
    "\n",
    "Other problem:\n",
    "try to optimize for temperature as well. If you change temperature from 3.5 to 1 I distill way better over the CNN and everything else as well\n",
    "\n",
    "Other problem:\n",
    "training very very unstable. If learning rate goes down from 0.001 to 0.1 all of the losses are nan (maybe because of the fact that the gradient is too high?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(69.3868)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6407, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "target = torch.Tensor([[ 0.0057,  0.0097,  0.0119,  0.0058, -0.0105, -0.0131,  0.0167,  0.0061,\n",
    "         0.0031, -0.0201], [ 0.0057,  0.0097,  0.0119,  0.0058, -0.0105, -0.0131,  0.0167,  0.0061,\n",
    "         0.0031, -0.0201]])\n",
    "input = torch.Tensor([[-17.5192,   0.3676, -10.2171,   3.7640,  -5.9923,  14.2353,  11.3412,\n",
    "        -20.4319,  -3.1274, -13.5950], [-17.5192,   0.3676, -10.2171,   3.7640,  -5.9923,  14.2353,  11.3412,\n",
    "        -20.4319,  -3.1274, -13.5950]])\n",
    "\n",
    "input = F.log_softmax(input/3.5, dim=1)\n",
    "target = F.softmax(target/3.5, dim=1)\n",
    "output = kl_loss(input, target) **3.5\n",
    "print(output)\n",
    "\n",
    "kl_loss = nn.KLDivLoss(reduction=\"batchmean\")\n",
    "# input should be a distribution in the log space\n",
    "input = F.log_softmax(torch.randn(3, 5, requires_grad=True), dim=1)\n",
    "# Sample a batch of distributions. Usually this would come from the dataset\n",
    "target = F.softmax(torch.rand(3, 5), dim=1)\n",
    "output = kl_loss(input, target)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_IM(test_loader, \u001b[43mmlp\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "test_IM(test_loader, mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1245, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, distiller.get_student())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------\n",
    "- Train 2 independent students with the same teacher, you compare the fidelities, if the 2 students have comparable fidelities they agree with the teacher because they generalize well\n",
    "- compute agreement metrics: how much has the student learnt to predict in the same way as the teacher. \n",
    "\n",
    "- self distilling mlp\n",
    "- distill an mlp over an mlp \n",
    "TO DO TOMORROW:\n",
    "- train an mlp independently on shifted data - compares with unshifted but distilled - then distilling \n",
    "- scale: extended MNIST CIFAR-10 (but cumbersome)\n",
    "- different MLP model size\n",
    "- large, heavy, regularized MLP\n",
    "- uncertainties : different seeds \n",
    "- 42 101 121 240 308 random seeds \n",
    "- non shifted training set + mlp, mlp with distillation on a cnn, run those over test dataset that's shifted -> expect better performance on mlp dist on cnn\n",
    "- give shifted validation set performance (validation set loss)\n",
    "- test val set accuracy with alpha different\n",
    "- cnn with data augmented\n",
    "- capire la cosa del softmax\n",
    "\n",
    "We need to have consistent:\n",
    "- training\n",
    "- distillation\n",
    "- indipendent metrics (ECE, NLL, topk) -> consistent with the literature \n",
    "- fidelity metrics\n",
    "----------------------------\n",
    "\n",
    "the model actually learns invariances through the teacher -> all of these results hold\n",
    "\n",
    "\n",
    "ECE,  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization Issues:\n",
    "Incorrect or inconsistent normalization of input features can cause training instability. Ensure that your input data is properly normalized.\n",
    "\n",
    "Complexity of the Model:\n",
    "If your model is too complex for the given task or if it has too many parameters, it may struggle to generalize well, leading to overfitting and erratic loss behavior. Consider simplifying the model architecture or using regularization techniques.\n",
    "\n",
    "Vanishing or Exploding Gradients:\n",
    "Problems like vanishing or exploding gradients can hinder the convergence of the model. Apply techniques such as gradient clipping, weight regularization, or normalization layers (e.g., Batch Normalization) to address these issues.\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "\n",
    "Learning Rate Too High:\n",
    "If the learning rate is set too high, the optimization algorithm might overshoot the minimum, leading to oscillations or divergence. Try reducing the learning rate and observe how it affects the training.\n",
    "\n",
    "Learning Rate Schedule:\n",
    "Sometimes, using a learning rate schedule or adaptive learning rate methods (such as learning rate annealing) can help stabilize the training process. These methods adjust the learning rate during training to improve convergence.\n",
    "\n",
    "Poor Initialization: \n",
    "The initial weights of the neural network can have a significant impact on training. Poor weight initialization may lead to difficulties in finding a good solution. Try using appropriate weight initialization techniques.\n",
    "\n",
    "Batch Size:\n",
    "The choice of batch size can also affect the stability of training. Smaller batch sizes may introduce more variability in the gradients, leading to fluctuations in the loss.\n",
    "\n",
    "Data Issues:\n",
    "Check the quality and consistency of your training data. Noisy or inconsistent data can make it challenging for the model to learn a meaningful representation.\n",
    "\n",
    "Early Stopping:\n",
    "If the loss does not improve over a certain number of epochs, it might be worth considering early stopping. Monitor the validation loss and stop training if it starts to increase consistently.\n",
    "\n",
    "Monitor Metrics Beyond Loss:\n",
    "Loss is just one metric, and it might not always reflect the performance of the model accurately. Monitor other metrics, such as accuracy or validation performance, to get a more comprehensive view of the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Test Accuracy: 0.9612\n",
      "tensor(0.8666, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Not using softmax\n",
      "tensor(0.8652, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "hfafu\n",
      "Epoch [1/5], Step [100/938], Student Loss : 1.6107, Total Loss: -2.4530\n",
      "Epoch [1/5], Step [200/938], Student Loss : 1.5491, Total Loss: -2.4538\n",
      "Epoch [1/5], Step [300/938], Student Loss : 1.5736, Total Loss: -2.4537\n",
      "Epoch [1/5], Step [400/938], Student Loss : 1.5053, Total Loss: -2.4579\n",
      "Epoch [1/5], Step [500/938], Student Loss : 1.5368, Total Loss: -2.4546\n",
      "Epoch [1/5], Step [600/938], Student Loss : 1.5078, Total Loss: -2.4571\n",
      "Epoch [1/5], Step [700/938], Student Loss : 1.5354, Total Loss: -2.4551\n",
      "Epoch [1/5], Step [800/938], Student Loss : 1.5270, Total Loss: -2.4570\n",
      "Epoch [1/5], Step [900/938], Student Loss : 1.4818, Total Loss: -2.4583\n",
      "Epoch [2/5], Step [100/938], Student Loss : 1.5084, Total Loss: -2.4583\n",
      "Epoch [2/5], Step [200/938], Student Loss : 1.5085, Total Loss: -2.4574\n",
      "Epoch [2/5], Step [300/938], Student Loss : 1.5143, Total Loss: -2.4574\n",
      "Epoch [2/5], Step [400/938], Student Loss : 1.5087, Total Loss: -2.4581\n",
      "Epoch [2/5], Step [500/938], Student Loss : 1.4948, Total Loss: -2.4570\n",
      "Epoch [2/5], Step [600/938], Student Loss : 1.4807, Total Loss: -2.4588\n",
      "Epoch [2/5], Step [700/938], Student Loss : 1.5185, Total Loss: -2.4543\n",
      "Epoch [2/5], Step [800/938], Student Loss : 1.5180, Total Loss: -2.4554\n",
      "Epoch [2/5], Step [900/938], Student Loss : 1.5298, Total Loss: -2.4553\n",
      "Epoch [3/5], Step [100/938], Student Loss : 1.5364, Total Loss: -2.4572\n",
      "Epoch [3/5], Step [200/938], Student Loss : 1.5043, Total Loss: -2.4561\n",
      "Epoch [3/5], Step [300/938], Student Loss : 1.5488, Total Loss: -2.4539\n",
      "Epoch [3/5], Step [400/938], Student Loss : 1.5448, Total Loss: -2.4557\n",
      "Epoch [3/5], Step [500/938], Student Loss : 1.4991, Total Loss: -2.4584\n",
      "Epoch [3/5], Step [600/938], Student Loss : 1.5519, Total Loss: -2.4562\n",
      "Epoch [3/5], Step [700/938], Student Loss : 1.5214, Total Loss: -2.4549\n",
      "Epoch [3/5], Step [800/938], Student Loss : 1.5240, Total Loss: -2.4561\n",
      "Epoch [3/5], Step [900/938], Student Loss : 1.5761, Total Loss: -2.4508\n",
      "Epoch [4/5], Step [100/938], Student Loss : 1.6029, Total Loss: -2.4524\n",
      "Epoch [4/5], Step [200/938], Student Loss : 1.5023, Total Loss: -2.4585\n",
      "Epoch [4/5], Step [300/938], Student Loss : 1.4872, Total Loss: -2.4573\n",
      "Epoch [4/5], Step [400/938], Student Loss : 1.5186, Total Loss: -2.4552\n",
      "Epoch [4/5], Step [500/938], Student Loss : 1.5208, Total Loss: -2.4579\n",
      "Epoch [4/5], Step [600/938], Student Loss : 1.5569, Total Loss: -2.4539\n",
      "Epoch [4/5], Step [700/938], Student Loss : 1.5276, Total Loss: -2.4563\n",
      "Epoch [4/5], Step [800/938], Student Loss : 1.5419, Total Loss: -2.4538\n",
      "Epoch [4/5], Step [900/938], Student Loss : 1.5168, Total Loss: -2.4553\n",
      "Epoch [5/5], Step [100/938], Student Loss : 1.5157, Total Loss: -2.4567\n",
      "Epoch [5/5], Step [200/938], Student Loss : 1.5287, Total Loss: -2.4575\n",
      "Epoch [5/5], Step [300/938], Student Loss : 1.5408, Total Loss: -2.4545\n",
      "Epoch [5/5], Step [400/938], Student Loss : 1.5072, Total Loss: -2.4568\n",
      "Epoch [5/5], Step [500/938], Student Loss : 1.5365, Total Loss: -2.4571\n",
      "Epoch [5/5], Step [600/938], Student Loss : 1.5237, Total Loss: -2.4561\n",
      "Epoch [5/5], Step [700/938], Student Loss : 1.5139, Total Loss: -2.4562\n",
      "Epoch [5/5], Step [800/938], Student Loss : 1.5379, Total Loss: -2.4550\n",
      "Epoch [5/5], Step [900/938], Student Loss : 1.4897, Total Loss: -2.4596\n",
      "Student loss: 1.5263379335403442\n",
      "Distillation loss: -2.4560436990525987\n",
      "Total loss: -2.4560436990525987\n",
      "saved model\n",
      "Test Accuracy: 0.9564\n"
     ]
    }
   ],
   "source": [
    "#Self distilling MLP (only from loaded data)\n",
    "\n",
    "#Self distillation: mlp_student and mlp teacher coincide #TODO CHECK\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "mlp_student.eval(test_loader)\n",
    "print(test_IM(test_loader, mlp_student))\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "print(test_IM(test_loader, mlp_teacher))\n",
    "\n",
    "if TRAIN:\n",
    "    selfdistiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    selfdistiller.distill(train_loader, 5, \"saved_models_selfdistill/\")\n",
    "    selfdistiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    selfdistiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_selfdistill/distiller')\n",
    "    selfdistiller.test_step(test_loader=test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1225, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, selfdistiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Not using softmax\n",
      "tensor(0.8675, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "hfafu\n",
      "Epoch [1/5], Step [100/938], Student Loss : 1.8133, Total Loss: -2.4328\n",
      "Epoch [1/5], Step [200/938], Student Loss : 1.6102, Total Loss: -2.4467\n",
      "Epoch [1/5], Step [300/938], Student Loss : 1.5824, Total Loss: -2.4507\n",
      "Epoch [1/5], Step [400/938], Student Loss : 1.5904, Total Loss: -2.4478\n",
      "Epoch [1/5], Step [500/938], Student Loss : 1.5991, Total Loss: -2.4521\n",
      "Epoch [1/5], Step [600/938], Student Loss : 1.6160, Total Loss: -2.4445\n",
      "Epoch [1/5], Step [700/938], Student Loss : 1.5626, Total Loss: -2.4541\n",
      "Epoch [1/5], Step [800/938], Student Loss : 1.5838, Total Loss: -2.4531\n",
      "Epoch [1/5], Step [900/938], Student Loss : 1.5454, Total Loss: -2.4517\n",
      "Epoch [2/5], Step [100/938], Student Loss : 1.5695, Total Loss: -2.4533\n",
      "Epoch [2/5], Step [200/938], Student Loss : 1.4950, Total Loss: -2.4567\n",
      "Epoch [2/5], Step [300/938], Student Loss : 1.5327, Total Loss: -2.4524\n",
      "Epoch [2/5], Step [400/938], Student Loss : 1.6156, Total Loss: -2.4503\n",
      "Epoch [2/5], Step [500/938], Student Loss : 1.5691, Total Loss: -2.4524\n",
      "Epoch [2/5], Step [600/938], Student Loss : 1.5940, Total Loss: -2.4529\n",
      "Epoch [2/5], Step [700/938], Student Loss : 1.5350, Total Loss: -2.4567\n",
      "Epoch [2/5], Step [800/938], Student Loss : 1.5776, Total Loss: -2.4500\n",
      "Epoch [2/5], Step [900/938], Student Loss : 1.5264, Total Loss: -2.4556\n",
      "Epoch [3/5], Step [100/938], Student Loss : 1.5526, Total Loss: -2.4572\n",
      "Epoch [3/5], Step [200/938], Student Loss : 1.5313, Total Loss: -2.4567\n",
      "Epoch [3/5], Step [300/938], Student Loss : 1.4924, Total Loss: -2.4560\n",
      "Epoch [3/5], Step [400/938], Student Loss : 1.5357, Total Loss: -2.4549\n",
      "Epoch [3/5], Step [500/938], Student Loss : 1.5297, Total Loss: -2.4562\n",
      "Epoch [3/5], Step [600/938], Student Loss : 1.5787, Total Loss: -2.4528\n",
      "Epoch [3/5], Step [700/938], Student Loss : 1.5350, Total Loss: -2.4558\n",
      "Epoch [3/5], Step [800/938], Student Loss : 1.5460, Total Loss: -2.4577\n",
      "Epoch [3/5], Step [900/938], Student Loss : 1.5596, Total Loss: -2.4503\n",
      "Epoch [4/5], Step [100/938], Student Loss : 1.5569, Total Loss: -2.4524\n",
      "Epoch [4/5], Step [200/938], Student Loss : 1.5000, Total Loss: -2.4574\n",
      "Epoch [4/5], Step [300/938], Student Loss : 1.6073, Total Loss: -2.4506\n",
      "Epoch [4/5], Step [400/938], Student Loss : 1.5375, Total Loss: -2.4510\n",
      "Epoch [4/5], Step [500/938], Student Loss : 1.5342, Total Loss: -2.4550\n",
      "Epoch [4/5], Step [600/938], Student Loss : 1.5382, Total Loss: -2.4546\n",
      "Epoch [4/5], Step [700/938], Student Loss : 1.5226, Total Loss: -2.4562\n",
      "Epoch [4/5], Step [800/938], Student Loss : 1.5501, Total Loss: -2.4557\n",
      "Epoch [4/5], Step [900/938], Student Loss : 1.4867, Total Loss: -2.4575\n",
      "Epoch [5/5], Step [100/938], Student Loss : 1.5320, Total Loss: -2.4556\n",
      "Epoch [5/5], Step [200/938], Student Loss : 1.5118, Total Loss: -2.4568\n",
      "Epoch [5/5], Step [300/938], Student Loss : 1.5380, Total Loss: -2.4567\n",
      "Epoch [5/5], Step [400/938], Student Loss : 1.5327, Total Loss: -2.4552\n",
      "Epoch [5/5], Step [500/938], Student Loss : 1.5520, Total Loss: -2.4561\n",
      "Epoch [5/5], Step [600/938], Student Loss : 1.5110, Total Loss: -2.4565\n",
      "Epoch [5/5], Step [700/938], Student Loss : 1.5391, Total Loss: -2.4557\n",
      "Epoch [5/5], Step [800/938], Student Loss : 1.5120, Total Loss: -2.4570\n",
      "Epoch [5/5], Step [900/938], Student Loss : 1.5121, Total Loss: -2.4562\n",
      "Student loss: 1.5545155922571818\n",
      "Distillation loss: -2.453506146536933\n",
      "Total loss: -2.453506146536933\n",
      "saved model\n",
      "Test Accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "#Distilling MLP from MLP\n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda')\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models/mlp\")\n",
    "print(test_IM(test_loader, mlp_teacher))\n",
    "\n",
    "if TRAIN:\n",
    "    mlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    mlp_mlp_distiller.distill(train_loader, 5, \"saved_models_mlpfrommlp/\")\n",
    "    mlp_mlp_distiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    mlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_mlpfrommlp/distiller')\n",
    "    mlp_mlp_distiller.test_step(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1270, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, mlp_mlp_distiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset that combines MNIST and additional data\n",
    "class ShiftAugmentedMNIST(Dataset):\n",
    "    def __init__(self, mnist_dataset, translation_times : int = 5, max_shift : int = 7):\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "        directions = [\"u\",\"d\",\"l\",\"r\"]\n",
    "        self.translations = []\n",
    "        for i in range(len(self.mnist_dataset)):\n",
    "            img, label = self.mnist_dataset[i]\n",
    "            img = img.squeeze()\n",
    "            for t in range(translation_times):\n",
    "                sh = shift_preserving_shape(img, direction=directions[np.random.randint(0,4)],\n",
    "                                            max_shift=max_shift).unsqueeze(0)\n",
    "                if sh is not None:\n",
    "                    self.translations.append((sh, label))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self.mnist_dataset):\n",
    "            return self.mnist_dataset[index]\n",
    "        else:\n",
    "            return self.translations[index - len(self.mnist_dataset)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset) + len(self.translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_augmented_dataset = ShiftAugmentedMNIST(train_dataset)\n",
    "train_augmented_loader = DataLoader(dataset=train_augmented_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Epoch [1/5], Step [100/5625], Loss: 1.4332\n",
      "Epoch [1/5], Step [200/5625], Loss: 1.2715\n",
      "Epoch [1/5], Step [300/5625], Loss: 0.9806\n",
      "Epoch [1/5], Step [400/5625], Loss: 0.6599\n",
      "Epoch [1/5], Step [500/5625], Loss: 0.4850\n",
      "Epoch [1/5], Step [600/5625], Loss: 0.6876\n",
      "Epoch [1/5], Step [700/5625], Loss: 0.3734\n",
      "Epoch [1/5], Step [800/5625], Loss: 0.4117\n",
      "Epoch [1/5], Step [900/5625], Loss: 0.5502\n",
      "Epoch [1/5], Step [1000/5625], Loss: 0.3068\n",
      "Epoch [1/5], Step [1100/5625], Loss: 0.3532\n",
      "Epoch [1/5], Step [1200/5625], Loss: 0.3167\n",
      "Epoch [1/5], Step [1300/5625], Loss: 0.2602\n",
      "Epoch [1/5], Step [1400/5625], Loss: 0.1548\n",
      "Epoch [1/5], Step [1500/5625], Loss: 0.3497\n",
      "Epoch [1/5], Step [1600/5625], Loss: 0.3821\n",
      "Epoch [1/5], Step [1700/5625], Loss: 0.3323\n",
      "Epoch [1/5], Step [1800/5625], Loss: 0.1482\n",
      "Epoch [1/5], Step [1900/5625], Loss: 0.4713\n",
      "Epoch [1/5], Step [2000/5625], Loss: 0.2970\n",
      "Epoch [1/5], Step [2100/5625], Loss: 0.5642\n",
      "Epoch [1/5], Step [2200/5625], Loss: 0.2986\n",
      "Epoch [1/5], Step [2300/5625], Loss: 0.2690\n",
      "Epoch [1/5], Step [2400/5625], Loss: 0.3755\n",
      "Epoch [1/5], Step [2500/5625], Loss: 0.2289\n",
      "Epoch [1/5], Step [2600/5625], Loss: 0.2848\n",
      "Epoch [1/5], Step [2700/5625], Loss: 0.1836\n",
      "Epoch [1/5], Step [2800/5625], Loss: 0.2984\n",
      "Epoch [1/5], Step [2900/5625], Loss: 0.2754\n",
      "Epoch [1/5], Step [3000/5625], Loss: 0.3038\n",
      "Epoch [1/5], Step [3100/5625], Loss: 0.1399\n",
      "Epoch [1/5], Step [3200/5625], Loss: 0.1599\n",
      "Epoch [1/5], Step [3300/5625], Loss: 0.1928\n",
      "Epoch [1/5], Step [3400/5625], Loss: 0.1422\n",
      "Epoch [1/5], Step [3500/5625], Loss: 0.2894\n",
      "Epoch [1/5], Step [3600/5625], Loss: 0.2790\n",
      "Epoch [1/5], Step [3700/5625], Loss: 0.1240\n",
      "Epoch [1/5], Step [3800/5625], Loss: 0.2227\n",
      "Epoch [1/5], Step [3900/5625], Loss: 0.2888\n",
      "Epoch [1/5], Step [4000/5625], Loss: 0.1220\n",
      "Epoch [1/5], Step [4100/5625], Loss: 0.2940\n",
      "Epoch [1/5], Step [4200/5625], Loss: 0.0622\n",
      "Epoch [1/5], Step [4300/5625], Loss: 0.1478\n",
      "Epoch [1/5], Step [4400/5625], Loss: 0.1204\n",
      "Epoch [1/5], Step [4500/5625], Loss: 0.2260\n",
      "Epoch [1/5], Step [4600/5625], Loss: 0.2048\n",
      "Epoch [1/5], Step [4700/5625], Loss: 0.2649\n",
      "Epoch [1/5], Step [4800/5625], Loss: 0.4703\n",
      "Epoch [1/5], Step [4900/5625], Loss: 0.0749\n",
      "Epoch [1/5], Step [5000/5625], Loss: 0.1190\n",
      "Epoch [1/5], Step [5100/5625], Loss: 0.1537\n",
      "Epoch [1/5], Step [5200/5625], Loss: 0.2951\n",
      "Epoch [1/5], Step [5300/5625], Loss: 0.1419\n",
      "Epoch [1/5], Step [5400/5625], Loss: 0.1271\n",
      "Epoch [1/5], Step [5500/5625], Loss: 0.1749\n",
      "Epoch [1/5], Step [5600/5625], Loss: 0.1750\n",
      "Epoch [2/5], Step [100/5625], Loss: 0.1902\n",
      "Epoch [2/5], Step [200/5625], Loss: 0.1419\n",
      "Epoch [2/5], Step [300/5625], Loss: 0.0704\n",
      "Epoch [2/5], Step [400/5625], Loss: 0.0641\n",
      "Epoch [2/5], Step [500/5625], Loss: 0.1618\n",
      "Epoch [2/5], Step [600/5625], Loss: 0.1698\n",
      "Epoch [2/5], Step [700/5625], Loss: 0.0382\n",
      "Epoch [2/5], Step [800/5625], Loss: 0.1359\n",
      "Epoch [2/5], Step [900/5625], Loss: 0.3849\n",
      "Epoch [2/5], Step [1000/5625], Loss: 0.0446\n",
      "Epoch [2/5], Step [1100/5625], Loss: 0.0235\n",
      "Epoch [2/5], Step [1200/5625], Loss: 0.2652\n",
      "Epoch [2/5], Step [1300/5625], Loss: 0.0421\n",
      "Epoch [2/5], Step [1400/5625], Loss: 0.1173\n",
      "Epoch [2/5], Step [1500/5625], Loss: 0.0259\n",
      "Epoch [2/5], Step [1600/5625], Loss: 0.1037\n",
      "Epoch [2/5], Step [1700/5625], Loss: 0.0819\n",
      "Epoch [2/5], Step [1800/5625], Loss: 0.0990\n",
      "Epoch [2/5], Step [1900/5625], Loss: 0.1472\n",
      "Epoch [2/5], Step [2000/5625], Loss: 0.2541\n",
      "Epoch [2/5], Step [2100/5625], Loss: 0.2973\n",
      "Epoch [2/5], Step [2200/5625], Loss: 0.2275\n",
      "Epoch [2/5], Step [2300/5625], Loss: 0.1974\n",
      "Epoch [2/5], Step [2400/5625], Loss: 0.0856\n",
      "Epoch [2/5], Step [2500/5625], Loss: 0.0307\n",
      "Epoch [2/5], Step [2600/5625], Loss: 0.1929\n",
      "Epoch [2/5], Step [2700/5625], Loss: 0.1274\n",
      "Epoch [2/5], Step [2800/5625], Loss: 0.1319\n",
      "Epoch [2/5], Step [2900/5625], Loss: 0.0701\n",
      "Epoch [2/5], Step [3000/5625], Loss: 0.0948\n",
      "Epoch [2/5], Step [3100/5625], Loss: 0.1120\n",
      "Epoch [2/5], Step [3200/5625], Loss: 0.0588\n",
      "Epoch [2/5], Step [3300/5625], Loss: 0.0761\n",
      "Epoch [2/5], Step [3400/5625], Loss: 0.1612\n",
      "Epoch [2/5], Step [3500/5625], Loss: 0.1310\n",
      "Epoch [2/5], Step [3600/5625], Loss: 0.1614\n",
      "Epoch [2/5], Step [3700/5625], Loss: 0.1081\n",
      "Epoch [2/5], Step [3800/5625], Loss: 0.0227\n",
      "Epoch [2/5], Step [3900/5625], Loss: 0.2509\n",
      "Epoch [2/5], Step [4000/5625], Loss: 0.0510\n",
      "Epoch [2/5], Step [4100/5625], Loss: 0.1035\n",
      "Epoch [2/5], Step [4200/5625], Loss: 0.0974\n",
      "Epoch [2/5], Step [4300/5625], Loss: 0.0959\n",
      "Epoch [2/5], Step [4400/5625], Loss: 0.1273\n",
      "Epoch [2/5], Step [4500/5625], Loss: 0.3123\n",
      "Epoch [2/5], Step [4600/5625], Loss: 0.2246\n",
      "Epoch [2/5], Step [4700/5625], Loss: 0.0820\n",
      "Epoch [2/5], Step [4800/5625], Loss: 0.2338\n",
      "Epoch [2/5], Step [4900/5625], Loss: 0.1395\n",
      "Epoch [2/5], Step [5000/5625], Loss: 0.0950\n",
      "Epoch [2/5], Step [5100/5625], Loss: 0.1264\n",
      "Epoch [2/5], Step [5200/5625], Loss: 0.2361\n",
      "Epoch [2/5], Step [5300/5625], Loss: 0.1898\n",
      "Epoch [2/5], Step [5400/5625], Loss: 0.1489\n",
      "Epoch [2/5], Step [5500/5625], Loss: 0.3006\n",
      "Epoch [2/5], Step [5600/5625], Loss: 0.1444\n",
      "Epoch [3/5], Step [100/5625], Loss: 0.0385\n",
      "Epoch [3/5], Step [200/5625], Loss: 0.1098\n",
      "Epoch [3/5], Step [300/5625], Loss: 0.0625\n",
      "Epoch [3/5], Step [400/5625], Loss: 0.0834\n",
      "Epoch [3/5], Step [500/5625], Loss: 0.0394\n",
      "Epoch [3/5], Step [600/5625], Loss: 0.1651\n",
      "Epoch [3/5], Step [700/5625], Loss: 0.2128\n",
      "Epoch [3/5], Step [800/5625], Loss: 0.1148\n",
      "Epoch [3/5], Step [900/5625], Loss: 0.1091\n",
      "Epoch [3/5], Step [1000/5625], Loss: 0.0945\n",
      "Epoch [3/5], Step [1100/5625], Loss: 0.2285\n",
      "Epoch [3/5], Step [1200/5625], Loss: 0.1825\n",
      "Epoch [3/5], Step [1300/5625], Loss: 0.1352\n",
      "Epoch [3/5], Step [1400/5625], Loss: 0.1150\n",
      "Epoch [3/5], Step [1500/5625], Loss: 0.1534\n",
      "Epoch [3/5], Step [1600/5625], Loss: 0.0674\n",
      "Epoch [3/5], Step [1700/5625], Loss: 0.1360\n",
      "Epoch [3/5], Step [1800/5625], Loss: 0.0457\n",
      "Epoch [3/5], Step [1900/5625], Loss: 0.0906\n",
      "Epoch [3/5], Step [2000/5625], Loss: 0.1029\n",
      "Epoch [3/5], Step [2100/5625], Loss: 0.0951\n",
      "Epoch [3/5], Step [2200/5625], Loss: 0.0820\n",
      "Epoch [3/5], Step [2300/5625], Loss: 0.0861\n",
      "Epoch [3/5], Step [2400/5625], Loss: 0.0868\n",
      "Epoch [3/5], Step [2500/5625], Loss: 0.0669\n",
      "Epoch [3/5], Step [2600/5625], Loss: 0.0570\n",
      "Epoch [3/5], Step [2700/5625], Loss: 0.1801\n",
      "Epoch [3/5], Step [2800/5625], Loss: 0.0111\n",
      "Epoch [3/5], Step [2900/5625], Loss: 0.0201\n",
      "Epoch [3/5], Step [3000/5625], Loss: 0.0358\n",
      "Epoch [3/5], Step [3100/5625], Loss: 0.0204\n",
      "Epoch [3/5], Step [3200/5625], Loss: 0.0621\n",
      "Epoch [3/5], Step [3300/5625], Loss: 0.0249\n",
      "Epoch [3/5], Step [3400/5625], Loss: 0.0287\n",
      "Epoch [3/5], Step [3500/5625], Loss: 0.0712\n",
      "Epoch [3/5], Step [3600/5625], Loss: 0.0772\n",
      "Epoch [3/5], Step [3700/5625], Loss: 0.0530\n",
      "Epoch [3/5], Step [3800/5625], Loss: 0.0392\n",
      "Epoch [3/5], Step [3900/5625], Loss: 0.0605\n",
      "Epoch [3/5], Step [4000/5625], Loss: 0.0673\n",
      "Epoch [3/5], Step [4100/5625], Loss: 0.1655\n",
      "Epoch [3/5], Step [4200/5625], Loss: 0.0780\n",
      "Epoch [3/5], Step [4300/5625], Loss: 0.0322\n",
      "Epoch [3/5], Step [4400/5625], Loss: 0.0845\n",
      "Epoch [3/5], Step [4500/5625], Loss: 0.2161\n",
      "Epoch [3/5], Step [4600/5625], Loss: 0.1500\n",
      "Epoch [3/5], Step [4700/5625], Loss: 0.0963\n",
      "Epoch [3/5], Step [4800/5625], Loss: 0.0807\n",
      "Epoch [3/5], Step [4900/5625], Loss: 0.0329\n",
      "Epoch [3/5], Step [5000/5625], Loss: 0.1709\n",
      "Epoch [3/5], Step [5100/5625], Loss: 0.0387\n",
      "Epoch [3/5], Step [5200/5625], Loss: 0.1502\n",
      "Epoch [3/5], Step [5300/5625], Loss: 0.0879\n",
      "Epoch [3/5], Step [5400/5625], Loss: 0.0125\n",
      "Epoch [3/5], Step [5500/5625], Loss: 0.1266\n",
      "Epoch [3/5], Step [5600/5625], Loss: 0.1098\n",
      "Epoch [4/5], Step [100/5625], Loss: 0.3617\n",
      "Epoch [4/5], Step [200/5625], Loss: 0.0429\n",
      "Epoch [4/5], Step [300/5625], Loss: 0.0694\n",
      "Epoch [4/5], Step [400/5625], Loss: 0.0576\n",
      "Epoch [4/5], Step [500/5625], Loss: 0.0754\n",
      "Epoch [4/5], Step [600/5625], Loss: 0.0178\n",
      "Epoch [4/5], Step [700/5625], Loss: 0.0123\n",
      "Epoch [4/5], Step [800/5625], Loss: 0.0472\n",
      "Epoch [4/5], Step [900/5625], Loss: 0.0718\n",
      "Epoch [4/5], Step [1000/5625], Loss: 0.0730\n",
      "Epoch [4/5], Step [1100/5625], Loss: 0.0074\n",
      "Epoch [4/5], Step [1200/5625], Loss: 0.0466\n",
      "Epoch [4/5], Step [1300/5625], Loss: 0.1129\n",
      "Epoch [4/5], Step [1400/5625], Loss: 0.0427\n",
      "Epoch [4/5], Step [1500/5625], Loss: 0.0090\n",
      "Epoch [4/5], Step [1600/5625], Loss: 0.0764\n",
      "Epoch [4/5], Step [1700/5625], Loss: 0.0565\n",
      "Epoch [4/5], Step [1800/5625], Loss: 0.0590\n",
      "Epoch [4/5], Step [1900/5625], Loss: 0.0116\n",
      "Epoch [4/5], Step [2000/5625], Loss: 0.1379\n",
      "Epoch [4/5], Step [2100/5625], Loss: 0.0465\n",
      "Epoch [4/5], Step [2200/5625], Loss: 0.0853\n",
      "Epoch [4/5], Step [2300/5625], Loss: 0.0458\n",
      "Epoch [4/5], Step [2400/5625], Loss: 0.1168\n",
      "Epoch [4/5], Step [2500/5625], Loss: 0.0599\n",
      "Epoch [4/5], Step [2600/5625], Loss: 0.0146\n",
      "Epoch [4/5], Step [2700/5625], Loss: 0.1221\n",
      "Epoch [4/5], Step [2800/5625], Loss: 0.0301\n",
      "Epoch [4/5], Step [2900/5625], Loss: 0.0358\n",
      "Epoch [4/5], Step [3000/5625], Loss: 0.0825\n",
      "Epoch [4/5], Step [3100/5625], Loss: 0.0325\n",
      "Epoch [4/5], Step [3200/5625], Loss: 0.1023\n",
      "Epoch [4/5], Step [3300/5625], Loss: 0.0089\n",
      "Epoch [4/5], Step [3400/5625], Loss: 0.0792\n",
      "Epoch [4/5], Step [3500/5625], Loss: 0.1531\n",
      "Epoch [4/5], Step [3600/5625], Loss: 0.0479\n",
      "Epoch [4/5], Step [3700/5625], Loss: 0.0164\n",
      "Epoch [4/5], Step [3800/5625], Loss: 0.1381\n",
      "Epoch [4/5], Step [3900/5625], Loss: 0.1549\n",
      "Epoch [4/5], Step [4000/5625], Loss: 0.0111\n",
      "Epoch [4/5], Step [4100/5625], Loss: 0.0709\n",
      "Epoch [4/5], Step [4200/5625], Loss: 0.0313\n",
      "Epoch [4/5], Step [4300/5625], Loss: 0.1134\n",
      "Epoch [4/5], Step [4400/5625], Loss: 0.0575\n",
      "Epoch [4/5], Step [4500/5625], Loss: 0.0645\n",
      "Epoch [4/5], Step [4600/5625], Loss: 0.0250\n",
      "Epoch [4/5], Step [4700/5625], Loss: 0.0376\n",
      "Epoch [4/5], Step [4800/5625], Loss: 0.0265\n",
      "Epoch [4/5], Step [4900/5625], Loss: 0.1111\n",
      "Epoch [4/5], Step [5000/5625], Loss: 0.0714\n",
      "Epoch [4/5], Step [5100/5625], Loss: 0.1223\n",
      "Epoch [4/5], Step [5200/5625], Loss: 0.0550\n",
      "Epoch [4/5], Step [5300/5625], Loss: 0.0902\n",
      "Epoch [4/5], Step [5400/5625], Loss: 0.1042\n",
      "Epoch [4/5], Step [5500/5625], Loss: 0.0648\n",
      "Epoch [4/5], Step [5600/5625], Loss: 0.0291\n",
      "Epoch [5/5], Step [100/5625], Loss: 0.1230\n",
      "Epoch [5/5], Step [200/5625], Loss: 0.1047\n",
      "Epoch [5/5], Step [300/5625], Loss: 0.1411\n",
      "Epoch [5/5], Step [400/5625], Loss: 0.0220\n",
      "Epoch [5/5], Step [500/5625], Loss: 0.0374\n",
      "Epoch [5/5], Step [600/5625], Loss: 0.0197\n",
      "Epoch [5/5], Step [700/5625], Loss: 0.1289\n",
      "Epoch [5/5], Step [800/5625], Loss: 0.0906\n",
      "Epoch [5/5], Step [900/5625], Loss: 0.0456\n",
      "Epoch [5/5], Step [1000/5625], Loss: 0.3653\n",
      "Epoch [5/5], Step [1100/5625], Loss: 0.0934\n",
      "Epoch [5/5], Step [1200/5625], Loss: 0.2809\n",
      "Epoch [5/5], Step [1300/5625], Loss: 0.0071\n",
      "Epoch [5/5], Step [1400/5625], Loss: 0.0495\n",
      "Epoch [5/5], Step [1500/5625], Loss: 0.0583\n",
      "Epoch [5/5], Step [1600/5625], Loss: 0.0198\n",
      "Epoch [5/5], Step [1700/5625], Loss: 0.0169\n",
      "Epoch [5/5], Step [1800/5625], Loss: 0.0540\n",
      "Epoch [5/5], Step [1900/5625], Loss: 0.0965\n",
      "Epoch [5/5], Step [2000/5625], Loss: 0.0915\n",
      "Epoch [5/5], Step [2100/5625], Loss: 0.1796\n",
      "Epoch [5/5], Step [2200/5625], Loss: 0.0630\n",
      "Epoch [5/5], Step [2300/5625], Loss: 0.0757\n",
      "Epoch [5/5], Step [2400/5625], Loss: 0.0468\n",
      "Epoch [5/5], Step [2500/5625], Loss: 0.0772\n",
      "Epoch [5/5], Step [2600/5625], Loss: 0.0301\n",
      "Epoch [5/5], Step [2700/5625], Loss: 0.0174\n",
      "Epoch [5/5], Step [2800/5625], Loss: 0.0153\n",
      "Epoch [5/5], Step [2900/5625], Loss: 0.1001\n",
      "Epoch [5/5], Step [3000/5625], Loss: 0.0535\n",
      "Epoch [5/5], Step [3100/5625], Loss: 0.1685\n",
      "Epoch [5/5], Step [3200/5625], Loss: 0.0222\n",
      "Epoch [5/5], Step [3300/5625], Loss: 0.0173\n",
      "Epoch [5/5], Step [3400/5625], Loss: 0.0425\n",
      "Epoch [5/5], Step [3500/5625], Loss: 0.0098\n",
      "Epoch [5/5], Step [3600/5625], Loss: 0.0074\n",
      "Epoch [5/5], Step [3700/5625], Loss: 0.0594\n",
      "Epoch [5/5], Step [3800/5625], Loss: 0.0444\n",
      "Epoch [5/5], Step [3900/5625], Loss: 0.0820\n",
      "Epoch [5/5], Step [4000/5625], Loss: 0.0174\n",
      "Epoch [5/5], Step [4100/5625], Loss: 0.1422\n",
      "Epoch [5/5], Step [4200/5625], Loss: 0.0812\n",
      "Epoch [5/5], Step [4300/5625], Loss: 0.1431\n",
      "Epoch [5/5], Step [4400/5625], Loss: 0.0715\n",
      "Epoch [5/5], Step [4500/5625], Loss: 0.1149\n",
      "Epoch [5/5], Step [4600/5625], Loss: 0.0418\n",
      "Epoch [5/5], Step [4700/5625], Loss: 0.0755\n",
      "Epoch [5/5], Step [4800/5625], Loss: 0.0267\n",
      "Epoch [5/5], Step [4900/5625], Loss: 0.0550\n",
      "Epoch [5/5], Step [5000/5625], Loss: 0.0158\n",
      "Epoch [5/5], Step [5100/5625], Loss: 0.1650\n",
      "Epoch [5/5], Step [5200/5625], Loss: 0.0563\n",
      "Epoch [5/5], Step [5300/5625], Loss: 0.0188\n",
      "Epoch [5/5], Step [5400/5625], Loss: 0.1015\n",
      "Epoch [5/5], Step [5500/5625], Loss: 0.0352\n",
      "Epoch [5/5], Step [5600/5625], Loss: 0.0120\n",
      "Model saved as saved_models_shiftinvariantmlp\\mlp!\n",
      "Test Accuracy: 0.9749\n"
     ]
    }
   ],
   "source": [
    "#Evaluating MLP trained on invariance data\n",
    "if TRAIN:\n",
    "    shift_invariant_mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "        hidden_layers= 4, device='cuda')\n",
    "    criterion_mlp = torch.nn.CrossEntropyLoss()\n",
    "    optimizer_mlp = torch.optim.Adam(shift_invariant_mlp.parameters(), lr=lr)\n",
    "    shift_invariant_mlp.train(train_loader=train_augmented_loader, optimizer=optimizer_mlp, criterion=criterion_mlp, \n",
    "              num_epochs=5, save_path_folder = \"saved_models_shiftinvariantmlp\")\n",
    "if not TRAIN:\n",
    "    shift_invariant_mlp = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models_shiftinvariantmlp/mlp\")\n",
    "shift_invariant_mlp.eval(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, shift_invariant_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using softmax\n",
      "Not using softmax\n",
      "Invariance of teacher:tensor(0.0821, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "Epoch [1/5], Step [100/938], Student Loss : 3.4604, Total Loss: 15.6608\n",
      "Epoch [1/5], Step [200/938], Student Loss : 2.1550, Total Loss: 3.0418\n",
      "Epoch [1/5], Step [300/938], Student Loss : 0.2299, Total Loss: 1.6676\n",
      "Epoch [1/5], Step [400/938], Student Loss : 0.9416, Total Loss: 2.1623\n",
      "Epoch [1/5], Step [500/938], Student Loss : 1.0407, Total Loss: 3.0659\n",
      "Epoch [1/5], Step [600/938], Student Loss : 0.8709, Total Loss: 2.0034\n",
      "Epoch [1/5], Step [700/938], Student Loss : 0.2186, Total Loss: 1.1539\n",
      "Epoch [1/5], Step [800/938], Student Loss : 0.1631, Total Loss: 1.0458\n",
      "Epoch [1/5], Step [900/938], Student Loss : 0.4773, Total Loss: 1.4397\n",
      "Epoch [2/5], Step [100/938], Student Loss : 0.3148, Total Loss: 1.6611\n",
      "Epoch [2/5], Step [200/938], Student Loss : 0.3473, Total Loss: 3.0052\n",
      "Epoch [2/5], Step [300/938], Student Loss : 0.5968, Total Loss: 1.6403\n",
      "Epoch [2/5], Step [400/938], Student Loss : 0.0611, Total Loss: 0.9886\n",
      "Epoch [2/5], Step [500/938], Student Loss : 0.2777, Total Loss: 0.6863\n",
      "Epoch [2/5], Step [600/938], Student Loss : 0.1147, Total Loss: 1.2115\n",
      "Epoch [2/5], Step [700/938], Student Loss : 0.2950, Total Loss: 1.3145\n",
      "Epoch [2/5], Step [800/938], Student Loss : 0.1428, Total Loss: 0.8588\n",
      "Epoch [2/5], Step [900/938], Student Loss : 0.2483, Total Loss: 1.2941\n",
      "Epoch [3/5], Step [100/938], Student Loss : 0.0389, Total Loss: 0.7593\n",
      "Epoch [3/5], Step [200/938], Student Loss : 0.0489, Total Loss: 0.6878\n",
      "Epoch [3/5], Step [300/938], Student Loss : 0.0317, Total Loss: 0.6488\n",
      "Epoch [3/5], Step [400/938], Student Loss : 0.0909, Total Loss: 0.9245\n",
      "Epoch [3/5], Step [500/938], Student Loss : 0.0056, Total Loss: 0.3832\n",
      "Epoch [3/5], Step [600/938], Student Loss : 0.0018, Total Loss: 1.0154\n",
      "Epoch [3/5], Step [700/938], Student Loss : 0.1075, Total Loss: 0.7496\n",
      "Epoch [3/5], Step [800/938], Student Loss : 0.2300, Total Loss: 1.1219\n",
      "Epoch [3/5], Step [900/938], Student Loss : 0.2168, Total Loss: 0.7760\n",
      "Epoch [4/5], Step [100/938], Student Loss : 0.0038, Total Loss: 0.4558\n",
      "Epoch [4/5], Step [200/938], Student Loss : 0.3084, Total Loss: 0.5788\n",
      "Epoch [4/5], Step [300/938], Student Loss : 0.1226, Total Loss: 0.4086\n",
      "Epoch [4/5], Step [400/938], Student Loss : 0.1236, Total Loss: 0.5367\n",
      "Epoch [4/5], Step [500/938], Student Loss : 0.1287, Total Loss: 0.3545\n",
      "Epoch [4/5], Step [600/938], Student Loss : 0.0657, Total Loss: 0.2820\n",
      "Epoch [4/5], Step [700/938], Student Loss : 0.0631, Total Loss: 0.4085\n",
      "Epoch [4/5], Step [800/938], Student Loss : 0.1821, Total Loss: 0.6157\n",
      "Epoch [4/5], Step [900/938], Student Loss : 0.0203, Total Loss: 0.4708\n",
      "Epoch [5/5], Step [100/938], Student Loss : 0.0946, Total Loss: 0.5327\n",
      "Epoch [5/5], Step [200/938], Student Loss : 0.0441, Total Loss: 0.3774\n",
      "Epoch [5/5], Step [300/938], Student Loss : 0.0548, Total Loss: 0.3114\n",
      "Epoch [5/5], Step [400/938], Student Loss : 0.0324, Total Loss: 0.4279\n",
      "Epoch [5/5], Step [500/938], Student Loss : 0.0542, Total Loss: 0.3380\n",
      "Epoch [5/5], Step [600/938], Student Loss : 0.3306, Total Loss: 0.4517\n",
      "Epoch [5/5], Step [700/938], Student Loss : 0.2335, Total Loss: 0.9449\n",
      "Epoch [5/5], Step [800/938], Student Loss : 0.0422, Total Loss: 0.4800\n",
      "Epoch [5/5], Step [900/938], Student Loss : 0.0081, Total Loss: 0.6415\n",
      "Student loss: 0.3253565156754727\n",
      "Distillation loss: 1.3241054289870793\n",
      "Total loss: 1.3241054289870793\n",
      "saved model\n",
      "Test Accuracy: 0.9844\n",
      "Test Accuracy: 0.9766\n",
      "Test Accuracy: 0.9740\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9750\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9688\n",
      "Test Accuracy: 0.9705\n",
      "Test Accuracy: 0.9656\n",
      "Test Accuracy: 0.9645\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9615\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9583\n",
      "Test Accuracy: 0.9580\n",
      "Test Accuracy: 0.9568\n",
      "Test Accuracy: 0.9566\n",
      "Test Accuracy: 0.9539\n",
      "Test Accuracy: 0.9508\n",
      "Test Accuracy: 0.9494\n",
      "Test Accuracy: 0.9503\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9469\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9456\n",
      "Test Accuracy: 0.9459\n",
      "Test Accuracy: 0.9456\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9466\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9458\n",
      "Test Accuracy: 0.9460\n",
      "Test Accuracy: 0.9457\n",
      "Test Accuracy: 0.9468\n",
      "Test Accuracy: 0.9461\n",
      "Test Accuracy: 0.9463\n",
      "Test Accuracy: 0.9465\n",
      "Test Accuracy: 0.9463\n",
      "Test Accuracy: 0.9464\n",
      "Test Accuracy: 0.9473\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9490\n",
      "Test Accuracy: 0.9487\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9480\n",
      "Test Accuracy: 0.9487\n",
      "Test Accuracy: 0.9488\n",
      "Test Accuracy: 0.9498\n",
      "Test Accuracy: 0.9493\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9495\n",
      "Test Accuracy: 0.9498\n",
      "Test Accuracy: 0.9504\n",
      "Test Accuracy: 0.9499\n",
      "Test Accuracy: 0.9495\n",
      "Test Accuracy: 0.9490\n",
      "Test Accuracy: 0.9486\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9480\n",
      "Test Accuracy: 0.9483\n",
      "Test Accuracy: 0.9479\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9472\n",
      "Test Accuracy: 0.9475\n",
      "Test Accuracy: 0.9475\n",
      "Test Accuracy: 0.9474\n",
      "Test Accuracy: 0.9473\n",
      "Test Accuracy: 0.9476\n",
      "Test Accuracy: 0.9478\n",
      "Test Accuracy: 0.9483\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9481\n",
      "Test Accuracy: 0.9477\n",
      "Test Accuracy: 0.9482\n",
      "Test Accuracy: 0.9484\n",
      "Test Accuracy: 0.9491\n",
      "Test Accuracy: 0.9497\n",
      "Test Accuracy: 0.9503\n",
      "Test Accuracy: 0.9509\n",
      "Test Accuracy: 0.9513\n",
      "Test Accuracy: 0.9515\n",
      "Test Accuracy: 0.9520\n",
      "Test Accuracy: 0.9522\n",
      "Test Accuracy: 0.9524\n",
      "Test Accuracy: 0.9526\n",
      "Test Accuracy: 0.9531\n",
      "Test Accuracy: 0.9523\n",
      "Test Accuracy: 0.9514\n",
      "Test Accuracy: 0.9511\n",
      "Test Accuracy: 0.9505\n",
      "Test Accuracy: 0.9505\n",
      "Test Accuracy: 0.9504\n",
      "Test Accuracy: 0.9509\n",
      "Test Accuracy: 0.9514\n",
      "Test Accuracy: 0.9519\n",
      "Test Accuracy: 0.9524\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9522\n",
      "Test Accuracy: 0.9527\n",
      "Test Accuracy: 0.9528\n",
      "Test Accuracy: 0.9531\n",
      "Test Accuracy: 0.9536\n",
      "Test Accuracy: 0.9540\n",
      "Test Accuracy: 0.9544\n",
      "Test Accuracy: 0.9547\n",
      "Test Accuracy: 0.9551\n",
      "Test Accuracy: 0.9553\n",
      "Test Accuracy: 0.9555\n",
      "Test Accuracy: 0.9558\n",
      "Test Accuracy: 0.9562\n",
      "Test Accuracy: 0.9562\n",
      "Test Accuracy: 0.9566\n",
      "Test Accuracy: 0.9569\n",
      "Test Accuracy: 0.9573\n",
      "Test Accuracy: 0.9575\n",
      "Test Accuracy: 0.9579\n",
      "Test Accuracy: 0.9580\n",
      "Test Accuracy: 0.9583\n",
      "Test Accuracy: 0.9586\n",
      "Test Accuracy: 0.9588\n",
      "Test Accuracy: 0.9588\n",
      "Test Accuracy: 0.9591\n",
      "Test Accuracy: 0.9593\n",
      "Test Accuracy: 0.9595\n",
      "Test Accuracy: 0.9593\n",
      "Test Accuracy: 0.9594\n",
      "Test Accuracy: 0.9595\n",
      "Test Accuracy: 0.9594\n",
      "Test Accuracy: 0.9597\n",
      "Test Accuracy: 0.9600\n",
      "Test Accuracy: 0.9603\n",
      "Test Accuracy: 0.9606\n",
      "Test Accuracy: 0.9608\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9612\n",
      "Test Accuracy: 0.9614\n",
      "Test Accuracy: 0.9616\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9622\n",
      "Test Accuracy: 0.9623\n",
      "Test Accuracy: 0.9625\n",
      "Test Accuracy: 0.9625\n",
      "Test Accuracy: 0.9621\n",
      "Test Accuracy: 0.9619\n",
      "Test Accuracy: 0.9615\n",
      "Test Accuracy: 0.9613\n",
      "Test Accuracy: 0.9610\n",
      "Test Accuracy: 0.9609\n",
      "Test Accuracy: 0.9610\n"
     ]
    }
   ],
   "source": [
    "#Train student model on this \n",
    "mlp_student = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda')\n",
    "\n",
    "mlp_teacher = MLP(input_dim = 784, output_dim= num_classes, hidden_size= 2048,\n",
    "            hidden_layers= 4, device='cuda', from_saved_state_dict=\"saved_models_shiftinvariantmlp/mlp\")\n",
    "print(\"Invariance of teacher:\" + str(test_IM(test_loader, mlp_teacher)))\n",
    "\n",
    "if TRAIN:\n",
    "    shiftinvmlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001)\n",
    "    shiftinvmlp_mlp_distiller.distill(train_loader, 5, \"saved_models_mlpfromshiftinvariantmlp/\")\n",
    "    shiftinvmlp_mlp_distiller.test_step(test_loader=test_loader)\n",
    "\n",
    "if not TRAIN:\n",
    "    print(\"Loading params\")\n",
    "    shiftinvmlp_mlp_distiller = Distiller(student=mlp_student, teacher=mlp_teacher, device='cuda', lr=0.001,\n",
    "                        load_student_from_path = 'saved_models_mlpfromshiftinvariantmlp/distiller')\n",
    "    shiftinvmlp_mlp_distiller.test_step(test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9111, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, shiftinvmlp_mlp_distiller.get_student())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_IM(test_loader, shiftinvmlp_mlp_distiller.get_student())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vanilla MLP -> 0.9\n",
    "CNN over MLP -> 0.6\n",
    "\n",
    "Self-distilled MLP -> 0.5\n",
    "MLP over MLP -> 0.5\n",
    "\n",
    "distilled MLP over data augmented MLP on non augmented dataset -> 0.48\n",
    "\n",
    "Data augmented MLP -> 0.09\n",
    "(distilled MLP over data augmented MLP on augmented dataset -> 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
